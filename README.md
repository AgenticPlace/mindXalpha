# Augmentic MindX: A Self-Improving AI System

## Overview

**MindX** is an experimental AI system developed under the conceptual "Augmentic Project." Its core design principle is **autonomous self-improvement**. MindX aims to analyze its own codebase, identify areas for enhancement, and apply these improvements, thereby evolving its capabilities over time. This project draws inspiration from concepts like the Darwin Gödel Machine, focusing on empirical validation of changes and maintaining a history of its evolution.

The system is architected around a suite of interacting agents:

-   **`CoordinatorAgent`**: The central orchestrator. It manages high-level tasks, performs system-wide analysis by integrating data from various sources (code structure, resource monitors, performance monitors), maintains an "improvement backlog," and delegates code modification tasks. It can operate an autonomous improvement loop with optional human-in-the-loop (HITL) for critical changes.
-   **`SelfImprovementAgent` (SIA)**: The specialized "code surgeon." Invoked via CLI by the Coordinator, the SIA takes a specific Python file and an improvement goal. It uses an LLM to generate code modifications, evaluates these changes (including running self-tests if modifying its own code), and employs safety mechanisms like iteration directories and fallbacks before promoting changes, especially for its own source code.
-   **Monitoring Agents (`ResourceMonitor`, `PerformanceMonitor`):** These agents track system health (CPU, memory, disk) and LLM interaction performance (latency, success rates, costs), providing crucial data that informs the Coordinator's analysis and decision-making.
-   **Utility Modules:** Supporting components for configuration management (`Config`), logging (`Logging`), LLM interaction (`LLMFactory`), and knowledge representation (`BeliefSystem`).

## Project Goals

-   To explore and implement mechanisms for AI self-improvement.
-   To create a system that can autonomously identify and apply beneficial modifications to its own source code.
-   To build a robust framework where self-improvement cycles are managed safely, with verification steps and fallback options.
-   To leverage Large Language Models (LLMs) for code analysis, generation, and critique within the self-improvement loop.
-   To provide a platform for experimenting with different strategies for autonomous AI development and evolution.

## Core Features

-   **Autonomous System Analysis:** The `CoordinatorAgent` can analyze the MindX codebase structure, current resource usage, and LLM performance to identify potential areas for improvement.
-   **Improvement Backlog:** Suggestions from system analysis are prioritized and managed in a persistent backlog.
-   **Autonomous Improvement Loop:** The `CoordinatorAgent` can periodically process the backlog, select high-priority improvements, and dispatch them.
-   **Human-in-the-Loop (HITL):** For changes to critical system components (like the Coordinator or SIA itself), the autonomous loop can be configured to require human approval before proceeding.
-   **Safe Code Modification (via `SelfImprovementAgent`):**
    -   **CLI Interface:** The SIA is invoked as a command-line tool, ensuring decoupling from the Coordinator.
    -   **Iteration Directories:** Self-modifications are performed and tested in isolated temporary directories.
    -   **Self-Tests:** Modified SIA code must pass a predefined suite of self-tests before being considered for promotion.
    -   **LLM-Critique:** LLMs are used to evaluate if the generated code meets the improvement goal.
    -   **Backup & Fallback:** Before promoting an update to its own script, the SIA creates a backup of the current version.
    -   **Robust JSON Output:** The SIA CLI provides structured JSON output detailing the outcome of its operations.
-   **Resource & Performance Monitoring:** Continuous tracking of system resources and LLM API performance provides data for informed decision-making.
-   **Configurable:** System behavior, LLM choices, thresholds, and feature toggles are managed via a central `Config` system that loads from `.env` files, a JSON config file, and environment variables.
-   **Modular Design:** Clear separation of responsibilities between agents and utility modules.

## Directory Structure
Use code with caution.
Markdown
augmentic_mindx/
├── mindx/ # Main MindX Python package
│ ├── core/ # Core concepts like BeliefSystem
│ ├── orchestration/ # CoordinatorAgent, (stubs for MMA, ModelSelector)
│ ├── learning/ # SelfImprovementAgent
│ ├── monitoring/ # ResourceMonitor, PerformanceMonitor
│ ├── llm/ # LLMFactory, LLMHandler
│ ├── utils/ # Config, Logging
│ └── docs/ # (Placeholder for documentation system)
├── scripts/ # CLI entry points
│ └── run_mindx_coordinator.py
├── data/ # Persistent data generated by MindX
│ ├── config/ # (Optional location for mindx_config.json)
│ ├── logs/ # Application logs
│ ├── self_improvement_work_sia/ # Data for SelfImprovementAgent
│ │ └── self_improve_agent/ # Subdir per SIA script name
│ │ ├── archive/ # SIA's detailed improvement history
│ │ └── fallback_versions/ # Backups of SIA script
│ ├── temp_sia_contexts/ # Temp files for Coordinator to SIA context
│ ├── improvement_backlog.json # Coordinator's backlog
│ ├── improvement_campaign_history.json # Coordinator's campaign log
│ └── performance_metrics.json # Data from PerformanceMonitor
├── tests/ # Unit and integration tests (placeholder)
├── .env # Environment variables (API keys, etc.)
├── mindx_config.json # Optional JSON configuration file (example)
├── pyproject.toml # Project metadata and dependencies
└── README.md # This file
## Getting Started

### Prerequisites

-   Python 3.9+
-   `pip` for installing dependencies
-   (Optional but Recommended) An Ollama server running locally if using Ollama models (e.g., for `deepseek-coder`, `nous-hermes2`). Download models:
    ```bash
    ollama pull deepseek-coder:6.7b-instruct
    ollama pull nous-hermes2
    ```
-   (Optional) Google Gemini API Key if using Gemini models.

### Installation

1.  **Clone the repository (if applicable).**
2.  **Create and activate a virtual environment:**
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # On Windows: .venv\Scripts\activate
    ```
3.  **Install dependencies:**
    From `pyproject.toml` (if you have one set up for the project):
    ```bash
    pip install . # or pip install .[dev] for development dependencies
    ```
    Or, install individually:
    ```bash
    pip install psutil python-dotenv ollama google-generativeai 
    # Add other LLM SDKs as needed
    ```

### Configuration

1.  **Copy `.env.example` to `.env` (if an example is provided) or create a new `.env` file** in the project root (`augmentic_mindx/`).
2.  **Edit `.env`** to include your API keys and preferred default LLM settings:

    ```env
    # --- General ---
    MINDX_LOG_LEVEL="INFO" # DEBUG, INFO, WARNING, ERROR

    # --- Default LLM Provider ---
    MINDX_LLM__DEFAULT_PROVIDER="ollama" # or "gemini"

    # --- Ollama Settings ---
    MINDX_LLM__OLLAMA__DEFAULT_MODEL="nous-hermes2:latest" 
    MINDX_LLM__OLLAMA__DEFAULT_MODEL_FOR_CODING="deepseek-coder:6.7b-instruct" 
    # MINDX_LLM__OLLAMA__BASE_URL="http://localhost:11434" # Default, uncomment if different

    # --- Gemini Settings ---
    GEMINI_API_KEY="YOUR_GEMINI_API_KEY_HERE" # Non-prefixed for direct SDK use if needed
    MINDX_LLM__GEMINI__API_KEY="YOUR_GEMINI_API_KEY_HERE" # Prefixed for Config system
    MINDX_LLM__GEMINI__DEFAULT_MODEL="gemini-1.5-flash-latest"
    MINDX_LLM__GEMINI__DEFAULT_MODEL_FOR_CODING="gemini-1.5-pro-latest"


    # --- Self Improvement Agent Specific LLM ---
    MINDX_SELF_IMPROVEMENT_AGENT__LLM__PROVIDER="ollama"
    MINDX_SELF_IMPROVEMENT_AGENT__LLM__MODEL="deepseek-coder:6.7b-instruct"

    # --- Coordinator Agent Specific LLM (for system analysis) ---
    MINDX_COORDINATOR__LLM__PROVIDER="ollama"
    MINDX_COORDINATOR__LLM__MODEL="nous-hermes2:latest"

    # --- Autonomous Improvement ---
    MINDX_COORDINATOR__AUTONOMOUS_IMPROVEMENT__ENABLED="false" # Set to "true" to enable
    MINDX_COORDINATOR__AUTONOMOUS_IMPROVEMENT__INTERVAL_SECONDS="3600" # e.g., 1 hour
    MINDX_COORDINATOR__AUTONOMOUS_IMPROVEMENT__REQUIRE_HUMAN_APPROVAL_FOR_CRITICAL="true"
    # Critical components are defined in config.py defaults or mindx_config.json
    ```
3.  (Optional) Create `mindx_config.json` in the project root or `data/config/` to override code defaults if preferred over environment variables for some settings. Environment variables (`MINDX_` prefixed) will always take the highest precedence.

### Running MindX

The primary way to interact with the system is through the `CoordinatorAgent`'s CLI:

```bash
python scripts/run_mindx_coordinator.py
Use code with caution.
Once the MindX CLI > prompt appears, you can issue commands:
help: Displays available commands.
query <your question>: Ask a general question.
MindX CLI > query What is the Dunning-Kruger effect?
Use code with caution.
analyze_system [optional focus for analysis]: Trigger a system-wide analysis. Suggestions will be added to the improvement backlog.
MindX CLI > analyze_system Focus on optimizing resource usage in monitoring agents.
Use code with caution.
improve <component_id> [optional improvement goal/context]: Request improvement for a specific component.
<component_id> is a Python module path (e.g., mindx.utils.config) or the special ID self_improve_agent_cli_mindx (to make the SIA improve itself).
MindX CLI > improve mindx.core.belief_system Add a method to get all belief keys matching a prefix.
MindX CLI > improve self_improve_agent_cli_mindx Enhance the detail in LLM critique justifications.
Use code with caution.
backlog: View the current improvement backlog.
process_backlog: Manually trigger the Coordinator to attempt the highest-priority actionable item from the backlog.
approve <backlog_item_id>: Approve a backlog item that is pending_approval. Get the ID from the backlog command.
reject <backlog_item_id>: Reject a pending_approval item.
quit or exit: Shut down the system.
Standalone SIA testing:
You can also test the SelfImprovementAgent directly (useful for debugging its core logic):
python mindx/learning/self_improve_agent.py self --context "Refactor the _ensure_directories_exist method to log more verbosely." --output-json
Use code with caution.
Bash
Current Status & Limitations
Core Loop Implemented: The CoordinatorAgent -> SelfImprovementAgent (CLI) -> LLM -> Code Change -> Evaluation -> Promotion (for SIA self-updates) loop is functional.
Safety Mechanisms: SIA includes iteration directories, self-tests (basic), backups, and fallbacks for its own code.
Autonomous Capabilities: The Coordinator has an autonomous loop with backlog management and HITL for critical changes.
Monitoring: Basic resource and LLM performance monitoring is in place.
LLM Dependency: The quality and success of improvements are heavily reliant on the capabilities of the configured LLMs.
Evaluation Robustness: The current evaluation within SIA (syntax check, self-tests, LLM critique) is a good start but could be significantly enhanced with:
Comprehensive unit and integration test execution against modified code.
Static analysis tools (linters, type checkers).
Performance benchmarking.
System Restart: After the SIA updates itself or the Coordinator, the running Python process uses the old code. A manual or external-supervisor-triggered restart is required for these changes to take effect. The system logs warnings and sets beliefs when this is needed.
Peripheral Agent Stubs: Components like MultiModelAgent, ModelSelector, BDIAgent, DocumentationAgent are currently functional stubs and would need full implementation for a complete MindX vision.
Error Handling: While improved, complex distributed systems can always benefit from more nuanced error recovery and state management.
Future Directions
Enhance the SIA's evaluation phase with automated test execution and static analysis.
Develop the peripheral agents (MultiModelAgent, BDIAgent, etc.) into fully functional components.
Implement more sophisticated strategies in the CoordinatorAgent for prioritizing backlog items and learning from past improvement successes/failures.
Explore mechanisms for automated system restart or dynamic module reloading after critical self-updates.
Expand the scope of self-improvement beyond single Python files (e.g., configuration files, documentation, multi-file refactoring).
